{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "class LangchainActions:\n",
    "\n",
    "    \n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    def __init__(self, user, host, password, name, dbType, file_name, model='gpt-4o'):\n",
    "        self.user = user\n",
    "        self.host = host\n",
    "        self.password = password\n",
    "        self.name = name\n",
    "        self.dbType = dbType\n",
    "        self.model = model\n",
    "        self.filename = file_name\n",
    "       \n",
    "\n",
    "    def createURI(self, dbType, tabelnames:list, rows=3):\n",
    "        if dbType == 'MySQL':\n",
    "            return SQLDatabase.from_uri(f\"mysql+pymysql://{self.user}:{self.password}@{self.host}/{self.name}\", sample_rows_in_table_info = rows, include_tables = tabelnames)\n",
    "        elif dbType == 'Postgres':\n",
    "            return SQLDatabase.from_uri(f\"postgresql+psycopg2://{self.user}:{self.password}@{self.host}/{self.name}\", sample_rows_in_table_info = rows, include_tables = tabelnames)\n",
    "\n",
    "    def get_table_details(self, filename):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        table_description = pd.read_csv(filename)\n",
    "        table_docs = []\n",
    "\n",
    "        # Iterate over the DataFrame rows to create Document objects\n",
    "        table_details = \"\"\n",
    "        for index, row in table_description.iterrows():\n",
    "            table_details = table_details + \"Table Name:\" + row['Table Name'].lower() + \"\\n\" + \"Table Description:\" + row['Description'] + \"\\n\\n\"\n",
    "\n",
    "        return table_details\n",
    "\n",
    "\n",
    "    def answer_query(self, question:str):\n",
    "        llm = ChatOpenAI(model = self.model, temperature=0)\n",
    "\n",
    "        table_details = self.get_table_details(self.filename)\n",
    "        table_details_prompt = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "        The tables are:\n",
    "\n",
    "        {table_details}\n",
    "\n",
    "        Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "\n",
    "        class Table(BaseModel):\n",
    "            \"\"\"Table in SQL database.\"\"\"\n",
    "\n",
    "            name: str = Field(description=\"Name of table in SQL database.\")\n",
    "\n",
    "        def get_tables(tables: List[Table]) -> List[str]:\n",
    "            tables  = [table.name for table in tables]\n",
    "            return tables\n",
    "        \n",
    "        select_table = {\"input\": itemgetter(\"question\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\n",
    "        tables = select_table.invoke({\"question\": question})\n",
    "        \n",
    "        db = self.createURI(self.dbType, tables)\n",
    "\n",
    "        generate_query = create_sql_query_chain(llm, db)\n",
    "        execute_query = QuerySQLDataBaseTool(db = db)\n",
    "        \n",
    "        answer_prompt = PromptTemplate.from_template(\n",
    "            \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "        Question: {question}\n",
    "        SQL Query: {query}\n",
    "        SQL Result: {result}\n",
    "        Answer: \"\"\"\n",
    "        )\n",
    "        rephrase_answer = answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "        def stripper(query:str):\n",
    "            # Adjust regex to capture content within ```sql and ```\n",
    "            match = re.search(r\"```sql\\n(.*?)\\n```\", query, re.DOTALL)\n",
    "            if match:\n",
    "                return (match.group(1)).replace('SQLQuery:', '').strip()\n",
    "            return None\n",
    "\n",
    "        chain = (\n",
    "            RunnablePassthrough.assign(query=generate_query)\n",
    "            .assign(clean_query=lambda x: stripper(x['query']))\n",
    "            .assign(result=itemgetter(\"clean_query\") | execute_query\n",
    "            )\n",
    "            | rephrase_answer\n",
    "        )\n",
    "\n",
    "        return chain.invoke({\"question\": question})\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain = LangchainActions(user=os.getenv('DB_USER'), host=os.getenv('DB_HOST'), password=os.getenv('DB_PASSWORD'), name=os.getenv('DB_NAME'), file_name = 'Hospital_Relational_Model.csv', dbType='Postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The top 5 test supplies are:\\n\\n1. Micropore with a total quantity of 48\\n2. Ryle's Tube with a total quantity of 42\\n3. Thermometers with a total quantity of 41\\n4. Torch with a total quantity of 40\\n5. Scissors with a total quantity of 40\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.answer_query('Top 5 test supplies')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
